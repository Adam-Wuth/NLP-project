{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c628a466-ecbf-46fb-94c9-dae7edb79f48",
   "metadata": {},
   "source": [
    "# NLP Project, Classification of Amazon Reviews and Key Phrases\n",
    "#### CSCI 3832 Natural Language Processing\n",
    "Members: Adam Wuth, Benjamin Kohav, Noah Vilas, Aiden Devine, Evan Zachary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde5fb9f-e2fe-4945-82aa-f19f9ea91c9d",
   "metadata": {},
   "source": [
    "### Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af68a2c9-d3bf-46d4-96ca-3b290fc42b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /opt/conda/lib/python3.10/site-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.10/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: triton==3.2.0 in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.10/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.10/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (2.8.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.10/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.10/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.10/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.10/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.9.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.5.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.30.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: fsspec[http]<=2024.12.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.3)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.23.5)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (22.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (1.5.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (22.2.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (2.1.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.8.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2022.12.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install nltk\n",
    "!pip install datasets\n",
    "import os, random, sys, copy\n",
    "import torch, torch.nn as nn, numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from nltk.tokenize import word_tokenize\n",
    "from datasets import load_dataset, concatenate_datasets, load_from_disk\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c120539f-c174-4e92-8749-d2a4c5ac5ed0",
   "metadata": {},
   "source": [
    "### Load in the data set\n",
    "The dataset is split into categories, but we wanted all categories from 2020 onwards. This code block will take forever to run, only run it the first time to get the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4fa836d-c97d-4466-ad7a-777f67274c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading category: All_Beauty\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1920a26ab0c4e6f8a0b708b176c5af5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/150000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading category: Amazon_Fashion\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ee27ef9d0a34525ade0fa213c17b72f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/150000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading category: Appliances\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e7e19eda7e1475faa8dbc835389c3bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/150000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading category: Arts_Crafts_and_Sewing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae7e91ebf3034b7aa8568c791112abf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/150000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading category: Automotive\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e12450425a14176bc20695965597b80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/150000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading category: Baby_Products\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c1643122bb249c4b75eaa1a025df8fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/150000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading category: Beauty_and_Personal_Care\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d02b5c79b5c04e479eae6499fa685246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/150000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading category: Books\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d76d8898bff2406e848ca37c347e3495",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/150000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading category: CDs_and_Vinyl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92c162e7a7a64055ac2fc041c50bb387",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/150000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading category: Cell_Phones_and_Accessories\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f22a35bce484099896ac29ef9a51e40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/150000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading category: Clothing_Shoes_and_Jewelry\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c32e06d71ca94973ad844703922f928f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/150000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading category: Digital_Music\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d993d1cac0004da09a8d3ea3128433d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/130434 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading category: Electronics\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9564901cd024c6eae913b8d4697718f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/150000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading category: Gift_Cards\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41c0e19183b54bd18fc18d03c970552e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/150000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading category: Grocery_and_Gourmet_Food\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29975618aa334542aef4caf420e1c23d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/150000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading category: Handmade_Products\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb46940196284873acaaec6abf691e52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/150000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading category: Health_and_Household\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae1479d1970d40eab7eb5b6cbf4d74b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/150000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading category: Health_and_Personal_Care\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4f5bb504e8c42bb9917fec47494b129",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/150000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading category: Home_and_Kitchen\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f02f596bfa4411788e0bd9c07d3adae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/150000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading category: Industrial_and_Scientific\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac0330e39c204676be415653e689709d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/150000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading category: Kindle_Store\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb7df3b7ec1742089e0d4620dced4935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/150000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading category: Magazine_Subscriptions\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c175a1bc848491d8317949285d5c88f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/71497 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading category: Movies_and_TV\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18be6255cdfa4f8eaec8f46d7191a6c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/150000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading category: Musical_Instruments\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5394ba0dd77a440c9ec08906a4a25545",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/150000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading category: Office_Products\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c4da5c04a754cfa9f3be59c84c0991a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/150000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading category: Patio_Lawn_and_Garden\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a63daedc11df4a34a74240ade584993f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/150000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading category: Pet_Supplies\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "412d1a7010404576ab0c373b9c42ac2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/150000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading category: Software\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b97a9cccb764d4babc8deb341b9ec99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/150000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading category: Sports_and_Outdoors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "441be48cb4c64a19b35618e746ea091a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/150000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading category: Subscription_Boxes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94b93d6085a14902bf05de1b6bea1d31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/16216 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading category: Tools_and_Home_Improvement\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8dd6ee913714cf4bb0f054181411eb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/150000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading category: Toys_and_Games\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f41a4e7a95834e3abf44d6c2ffaf83cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/150000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading category: Video_Games\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03ca9105e236494cbe51a3772940d845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/150000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading category: Unknown\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f798df528324b36be78630301a3f2ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/150000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reviews loaded: 120088\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "141e67cb1b0d480ca7e084adcb2f9cd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/120088 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#The dataset is split into categories\n",
    "\n",
    "categories = [\n",
    "    \"All_Beauty\",\n",
    "    \"Amazon_Fashion\",\n",
    "    \"Appliances\",\n",
    "    \"Arts_Crafts_and_Sewing\",\n",
    "    \"Automotive\",\n",
    "    \"Baby_Products\",\n",
    "    \"Beauty_and_Personal_Care\",\n",
    "    \"Books\",\n",
    "    \"CDs_and_Vinyl\",\n",
    "    \"Cell_Phones_and_Accessories\",\n",
    "    \"Clothing_Shoes_and_Jewelry\",\n",
    "    \"Digital_Music\",\n",
    "    \"Electronics\",\n",
    "    \"Gift_Cards\",\n",
    "    \"Grocery_and_Gourmet_Food\",\n",
    "    \"Handmade_Products\",\n",
    "    \"Health_and_Household\",\n",
    "    \"Health_and_Personal_Care\",\n",
    "    \"Home_and_Kitchen\",\n",
    "    \"Industrial_and_Scientific\",\n",
    "    \"Kindle_Store\",\n",
    "    \"Magazine_Subscriptions\",\n",
    "    \"Movies_and_TV\",\n",
    "    \"Musical_Instruments\",\n",
    "    \"Office_Products\",\n",
    "    \"Patio_Lawn_and_Garden\",\n",
    "    \"Pet_Supplies\",\n",
    "    \"Software\",\n",
    "    \"Sports_and_Outdoors\",\n",
    "    \"Subscription_Boxes\",\n",
    "    \"Tools_and_Home_Improvement\",\n",
    "    \"Toys_and_Games\",\n",
    "    \"Video_Games\",\n",
    "    \"Unknown\"\n",
    "]\n",
    "\n",
    "#to get reviews from 2023 onwards 2020 onwards was millions of reviews and was taking\n",
    "#over an hour just to load the data\n",
    "start_timestamp = int(datetime(2023, 1, 1).timestamp() * 1000)\n",
    "\n",
    "#to store all datasets\n",
    "allcats = []\n",
    "\n",
    "for cat in categories:\n",
    "    print(f\"Loading category: {cat}\")\n",
    "    dataset = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", f\"raw_review_{cat}\", split=\"full[:150000]\",  trust_remote_code=True)\n",
    "    #dataset = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", f\"raw_review_{cat}\", split=\"full[:1%]\",  trust_remote_code=True)\n",
    "   #dataset = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", cat, split=\"full\",  trust_remote_code=True) formatting issues\n",
    "    #get the 2023 onwards and add to data\n",
    "    filtered_dataset = dataset.filter(lambda x: x['timestamp'] >= start_timestamp)\n",
    "    #allcats.append(dataset)\n",
    "    allcats.append(filtered_dataset)\n",
    "#make one final dataset    \n",
    "reviews = concatenate_datasets(allcats)\n",
    "\n",
    "print(f\"Total reviews loaded: {len(reviews)}\")\n",
    "\n",
    "reviews.save_to_disk(\"filetred_amazon_reviews\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfff221-5127-4716-ae61-7d96e01082b4",
   "metadata": {},
   "source": [
    "If you have run that already, reviews was saved(should be in the working directory)so you can just do the next code block instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c08d7f81-c990-4b7f-b566-4bee0cd6b8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120088\n",
      "{'rating': 1.0, 'title': 'halo hair extensions', 'text': \"This halo hair extension is simply put, garbage.  Now, you get what you pay for.  And this is a very cheap version.  The faux hair is very shiny and looks literally like bad barbie hair.  It looks WAY better in the photos than in real life.  The color is horrific, in my opinion of course.  The streaks are like paint strips.  And all of that would be one thing - but the worst is that the hair completely fell out!  I had hand fulls of hair strands just trying to put the halo on!  And you might think - well, maybe a little loss is to be expected?  Except this was handfuls and handfuls.  I literally dropped the whole thing right into the trash.  I would say this one is a pass for hair loss alone.  Having said all of this, I never hesitate to update my reviews should new info seem useful. All of my reviews reflect my honest, personal experience with the reviewed item - your experience may be different. I am not influenced by any outside source. I receive/accept NO free products or discounts that are not available to all shoppers- ever. For some reason our shopper ranks are no longer visible - so, to give you a little more info about me, I am a top 50 reviewer (#30 the highest rank achieved). Those numbers used to fluctuate over time - up and down but I noticed that they stopped updating regularly - perhaps to phase them out. It's a shame because it did help you see who has been around the longest and who is a trustworthy reviewer.\\xa0 I've been doing reviews for over 25 years with Amazon - over 6,000 reviews posted, those reviews have been viewed well over 50,000 times, including well over 25,000 likes. Bottom line, I pay for all my stuff, just like you do.\", 'images': [], 'asin': 'B0BFR5WF1R', 'parent_asin': 'B0BFR5WF1R', 'user_id': 'AFZUK3MTBIBEDQOPAK3OATUOUKLA', 'timestamp': 1675826333052, 'helpful_vote': 4, 'verified_purchase': True}\n",
      "{'rating': 1.0, 'title': 'Crap', 'text': \"These look and fit BAD.<br />Fake looking.<br />Not dentures fake- Halloween fake.<br />Plus they don't conform in your mouth. They are bulky. They require major adjustments with power tools to fit properly. These are a joke. If your getting them for a prank or to play dress up, I guess they’d do.<br />If you need a decent temporary smile that looks and feels good, go with Imako.\", 'images': [], 'asin': 'B0BL3HSBZB', 'parent_asin': 'B0BL3HSBZB', 'user_id': 'AF5PN3FPG5Z66P7Z7UWL56D6CGMA', 'timestamp': 1674411398983, 'helpful_vote': 0, 'verified_purchase': True}\n",
      "['rating', 'title', 'text', 'images', 'asin', 'parent_asin', 'user_id', 'timestamp', 'helpful_vote', 'verified_purchase']\n"
     ]
    }
   ],
   "source": [
    "reviews = load_from_disk(\"filetred_amazon_reviews\")\n",
    "print(len(reviews))\n",
    "print(reviews[0])\n",
    "print(reviews[1])\n",
    "print(reviews.column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa7db25-207c-4d3b-aa91-d315ef26d63a",
   "metadata": {},
   "source": [
    "### Load in the Glove Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04cb23a5-a488-47ec-b8d0-fa8233edb8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 words from glove\n"
     ]
    }
   ],
   "source": [
    "glove_file = '../glove.6B.50d.txt' # modify to appropriate path for your file system\n",
    "\n",
    "embeddings_dict = {}\n",
    "\n",
    "with open(glove_file, 'r', encoding='utf8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        line = line.strip().split(' ')\n",
    "        word = line[0]\n",
    "        embed = np.asarray(line[1:], \"float\")\n",
    "\n",
    "        embeddings_dict[word] = embed\n",
    "\n",
    "\n",
    "print('Loaded {} words from glove'.format(len(embeddings_dict)))\n",
    "\n",
    "low = -1.0 / 3\n",
    "high = 1.0 / 3\n",
    "embedding_matrix = np.random.uniform(low=low, high=high, size=(len(embeddings_dict)+1, 50))\n",
    "\n",
    "word2id = {}\n",
    "for i, word in enumerate(embeddings_dict.keys(), 1):\n",
    "\n",
    "    word2id[word] = i                                \n",
    "    embedding_matrix[i] = embeddings_dict[word]      \n",
    "\n",
    "word2id['<pad>'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3285fb2a-1724-4b04-ad9f-3f94f49c3416",
   "metadata": {},
   "source": [
    "### Set up train and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07452ee5-c85e-47d9-8669-72b8ce6fca49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modified from the HW_3 \n",
    "class RNNMovieReviewDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, hf_dataset=None, word2id=None, finalized_data=None, data_limit=250, max_length=128):\n",
    "        \"\"\"\n",
    "        :param hf_dataset: A Hugging Face Dataset object (preloaded and filtered)\n",
    "        :param word2id: The GloVe word2id dictionary\n",
    "        :param finalized_data: Used to create validation set\n",
    "        :param data_limit: Max number of examples to use\n",
    "        :param max_length: Max sequence length\n",
    "        \"\"\"\n",
    "        self.data_limit = data_limit\n",
    "        self.max_length = max_length\n",
    "        self.word2id = word2id\n",
    "\n",
    "        if finalized_data:\n",
    "            self.data = finalized_data\n",
    "        else:\n",
    "            examples = []\n",
    "            labels = []\n",
    "\n",
    "            for i, example in enumerate(hf_dataset):\n",
    "                if i >= self.data_limit:\n",
    "                    break\n",
    "                examples.append(example[\"text\"])\n",
    "                labels.append(int(example[\"rating\"]) - 1)  # 1–5 stars → 0–4\n",
    "\n",
    "            tokenized = self.tokenize(examples)\n",
    "            self.data = [(ids, length, label) for (ids, length), label in zip(tokenized, labels)]\n",
    "            random.seed(42)\n",
    "            random.shuffle(self.data)\n",
    "\n",
    "    def tokenize(self, examples):\n",
    "        example_ids = []\n",
    "        misses = 0\n",
    "        total = 0\n",
    "        for example in tqdm(examples):\n",
    "            tokens = word_tokenize(example)\n",
    "            ids = []\n",
    "            for tok in tokens:\n",
    "                if tok in self.word2id:\n",
    "                    ids.append(self.word2id[tok])\n",
    "                else:\n",
    "                    misses += 1\n",
    "                    ids.append(self.word2id.get('unk', 0))\n",
    "                total += 1\n",
    "            \n",
    "            if len(ids) == 0:\n",
    "                continue\n",
    "            \n",
    "            if len(ids) >= self.max_length:\n",
    "                ids = ids[:self.max_length]\n",
    "                length = self.max_length\n",
    "            else:\n",
    "                length = len(ids)\n",
    "                ids += [self.word2id['<pad>']] * (self.max_length - len(ids))\n",
    "\n",
    "            example_ids.append((torch.tensor(ids), length))\n",
    "\n",
    "        print(f'Missed {misses} out of {total} words -- {misses/total:.2%}')\n",
    "        return example_ids\n",
    "\n",
    "    def generate_validation_split(self, ratio=0.8):\n",
    "        split_idx = int(ratio * len(self.data))\n",
    "        val_split = self.data[split_idx:]\n",
    "        self.data = self.data[:split_idx]\n",
    "        return val_split\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]  # returns (input_ids, length, label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b77ae593-a49e-4488-8d8f-4f1e2125803c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a44e9dfa821e468fb5c5603e8716d0d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missed 656201 out of 5940281 words -- 11.05%\n",
      "Loaded 79924 train examples\n",
      "Loaded 19982 validation examples\n",
      "(tensor([201535,   2556,      2,   2041,   3273,  35268,      2,    841,   5006,\n",
      "             3, 201535,   4239,  10016,     11,   1282,    416, 201535,  19796,\n",
      "         30411,    275,  12258, 201535,      4,      8,    144,   5702,   7936,\n",
      "          1931,      2,     64,     16,  73976,   2756,      3, 201535,    863,\n",
      "          2401,      2,     21,     15,      8,   7936,   2366,     35,     21,\n",
      "         66020,   3072,   2160,   9787,     18,      1,    884,     23,     65,\n",
      "             3,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0]), 55, 4)\n"
     ]
    }
   ],
   "source": [
    "#also modified from hw3\n",
    "train_dataset = RNNMovieReviewDataset(hf_dataset=reviews, word2id=word2id, data_limit=100000)\n",
    "validation_examples = train_dataset.generate_validation_split()\n",
    "print('Loaded {} train examples'.format(len(train_dataset)))\n",
    "\n",
    "valid_dataset = RNNMovieReviewDataset(finalized_data=validation_examples, word2id=word2id)\n",
    "print('Loaded {} validation examples'.format(len(valid_dataset)))\n",
    "\n",
    "print(valid_dataset[0])  # (input_ids, length, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "442cbf7c-2609-439d-8cd1-a4c757c2e8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True length: 34\n",
      "Non-padded input: tensor([201535,     15,      1,   4054,     80,     42,     34,   3169,      1,\n",
      "          8378,  22645,   3263,      3, 201535,   3388,      8,    531,      6,\n",
      "           159,   3263,    276,      5,    579,    193,  18133,   2432,      3,\n",
      "        201535,     87,  31287,    102,   1690,    457,      3])\n",
      "Label: 4\n"
     ]
    }
   ],
   "source": [
    "input_ids, length, label = valid_dataset[1]\n",
    "print(\"True length:\", length)\n",
    "print(\"Non-padded input:\", input_ids[:length])\n",
    "print(\"Label:\", label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8addb396-997d-4bbd-b7fc-3c35f8224998",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_matrix, lstm_hidden_size=50, num_lstm_layers=1, bidirectional=True, stats=False):\n",
    "\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(embedding_matrix))\n",
    "        self.lstm = nn.LSTM(input_size = embedding_matrix.shape[1],\n",
    "                            hidden_size = lstm_hidden_size,\n",
    "                            num_layers = num_lstm_layers,\n",
    "                            bidirectional = bidirectional,\n",
    "                            batch_first = True)\n",
    "        \n",
    "        self.hidden_1 = nn.Linear(lstm_hidden_size * 2, lstm_hidden_size)\n",
    "        self.hidden_2 = nn.Linear(lstm_hidden_size, 5)\n",
    "        self.num_directions = 2 if bidirectional else 1\n",
    "        self.relu = nn.ReLU()\n",
    "        self.stats = stats\n",
    "\n",
    "    def forward(self, input_batch, input_lengths):\n",
    "        \n",
    "        if self.stats: print(\"input_batch: \", input_batch.shape)\n",
    "        \n",
    "        embedded_input = self.embedding(input_batch)\n",
    "        if self.stats: print(\"embedded_input:\", embedded_input.shape)\n",
    "        \n",
    "        packed_input = pack_padded_sequence(embedded_input, input_lengths, batch_first=True, enforce_sorted=False)\n",
    "\n",
    "        packed_output, (hn, cn) = self.lstm(packed_input) # See docs linked below for description of hn.shape\n",
    "        if self.stats: print(\"hn:\", hn.shape)\n",
    "        \n",
    "        hn_view = hn.view(self.lstm.num_layers, self.num_directions, input_batch.shape[0], self.lstm.hidden_size)               # Reshape hn for clarity -- first dimension now represents each layer (total set by num_lstm_layers)\n",
    "        if self.stats: print(\"hn_view:\", hn_view.shape)\n",
    "        \n",
    "        hn_view_last_layer = hn_view[-1]                                                                                        # Taking the last layer for our final LSTM output\n",
    "        if self.stats: print(\"hn_view_last_layer:\", hn_view_last_layer.shape)\n",
    "        \n",
    "        hn_cat = torch.cat([hn_view_last_layer[-2, :, :], hn_view_last_layer[-1, :, :]], dim=1)                                 # Each layer has two directions. We want to use both of these vectors, so concatenate them\n",
    "        if self.stats: print(\"hn_cat:\", hn_cat.shape)\n",
    "        \n",
    "        hid = self.relu(self.hidden_1(hn_cat))\n",
    "        if self.stats: print(\"hid:\", hid.shape)\n",
    "        \n",
    "        output = self.hidden_2(hid)\n",
    "        if self.stats: print(\"output:\", output.shape)\n",
    "        \n",
    "        # raise KeyError\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3973cc86-1cfa-4ffd-a89c-7cace1bacb7d",
   "metadata": {},
   "source": [
    "removed sigmoid because 5 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00dec285-53bc-42c6-9582-94029900dfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, valid_dataloader):\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_examples = len(valid_dataloader.dataset)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (x, x_lengths), y in valid_dataloader:\n",
    "            logits = model(x, x_lengths)               # Shape: [batch_size, 5]\n",
    "            preds = torch.argmax(logits, dim=1)        # Pick highest logit class\n",
    "            total_correct += (preds == y).sum().item()\n",
    "\n",
    "    accuracy = total_correct / total_examples\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a62dd1-fa99-4b35-967b-9239cd88388f",
   "metadata": {},
   "source": [
    "Changed BCEWithLogitsLoss() to CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22eea82f-73f8-463d-8b86-3b4324e30520",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lstm_classification(model, train_dataset, valid_dataset, epochs=10, batch_size=32, learning_rate=.001, print_frequency=25):\n",
    "\n",
    "    criteria = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    #We'll create an instance of a torch dataloader to collate our data. This class handles batching and shuffling (should be done each epoch)\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    valid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "    print('Total train batches: {}'.format(train_dataset.__len__() / batch_size))\n",
    "\n",
    "    best_accuracy = 0.0\n",
    "    best_model_sd = None\n",
    "\n",
    "    for i in range(epochs):\n",
    "        print('### Epoch: ' + str(i+1) + ' ###')\n",
    "    \n",
    "        model.train()\n",
    "\n",
    "        avg_loss = 0\n",
    "\n",
    "        for step, data in enumerate(tqdm(train_dataloader, desc=f\"Training Epoch {i+1}\")):\n",
    "\n",
    "            x, x_lengths, y = data\t# Our dataset is returning the input example x and also the lengths of the examples, so we'll unpack that here\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            model_output = model(x, x_lengths)\n",
    "\n",
    "            loss = criteria(model_output, y)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            avg_loss += loss.item()\n",
    "\n",
    "            if step % print_frequency == (print_frequency - 1):\n",
    "                print('epoch: {} batch: {} loss: {}'.format(\n",
    "                    i,\n",
    "                    step,\n",
    "                    avg_loss / print_frequency\n",
    "                ))\n",
    "                avg_loss = 0\n",
    "\n",
    "        print('Evaluating...')\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            acc = predict(model, valid_dataloader)\n",
    "            if acc > best_accuracy:\n",
    "                best_model_sd = copy.deepcopy(model.state_dict())\n",
    "                best_accuracy = acc\n",
    "\n",
    "    return model.state_dict(), best_model_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fc64b6-1cfb-44fd-87dc-a6bf9de3bb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train batches: 624.40625\n",
      "### Epoch: 1 ###\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff937a149211470d81c2f4de50c6d12b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 1:   0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = LSTMModel(embedding_matrix, lstm_hidden_size=50, num_lstm_layers=2, bidirectional=True)\n",
    "\n",
    "final_model_state, best_model_state = train_lstm_classification(\n",
    "    model,\n",
    "    train_dataset,\n",
    "    valid_dataset,\n",
    "    epochs=5,             \n",
    "    batch_size=128,\n",
    "    learning_rate=1e-3,\n",
    "    print_frequency=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c1a7a4-c14f-44d3-a7a7-a254cb57db50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
